{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network_classifier_JAX.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4K4OCaPhyQ5",
        "outputId": "5a232760-f264-4d95-b402-f5bcd74b9ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.scipy.special import logsumexp\n",
        "import numpy as np\n",
        "from jax import jit, vmap, grad, value_and_grad, pmap\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "key = jax.random.PRNGKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(layer_widths,parent_key, scale=0.01):\n",
        "\n",
        "  params = []\n",
        "  for p, q, key in zip(layer_widths[:-1], layer_widths[1:], jax.random.split(parent_key, num=len(layer_widths)-1)):\n",
        "    w, b = jax.random.split(key)\n",
        "    params.append([scale*jax.random.normal(w, shape=(q, p)), scale*jax.random.normal(b, shape=(q,))])\n",
        "  return params\n",
        "\n",
        "print(jax.tree_map(lambda x:x.shape,perceptron([784,512,256,10],key)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYdURCUSiu7W",
        "outputId": "3e488539-ed5e-4b55-a065-5df96d221d84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(512, 784), (512,)], [(256, 512), (256,)], [(10, 256), (10,)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(params, x):\n",
        "  hidden_layers = params[:-1]\n",
        "  activation = x\n",
        "  for w, b in hidden_layers:\n",
        "    activation = jax.nn.relu(jnp.dot(w,activation)+b)\n",
        "\n",
        "  w_last, b_last = params[-1]\n",
        "  logits = jnp.dot(w_last, activation)+b_last\n",
        "  return logits - logsumexp(logits)\n",
        "\n",
        "batched_MLP_predict = vmap(predict, in_axes=(None,0))"
      ],
      "metadata": {
        "id": "N3Cd5bhii5ag"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_transform(x):\n",
        "  return np.ravel(np.array(x, dtype=np.float32))\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "  transposed_data = list(zip(*batch))\n",
        "\n",
        "  labels = np.array(transposed_data[1])\n",
        "  imgs = np.array(transposed_data[0])\n",
        "  return imgs,labels\n",
        "\n",
        "\n",
        "train_dataset = MNIST(root='train_mnist', train=True, download= True, transform=custom_transform)\n",
        "test_dataset = MNIST(root='test_mnist', train= False, download= True, transform = custom_transform )\n",
        "batch_size = 128\n",
        "img = train_dataset[0][0]\n",
        "print(img.shape)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, sampler=None,collate_fn= custom_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)\n",
        "\n",
        "batch_data = next(iter(train_loader))\n",
        "imgs = batch_data[0]\n",
        "lbls = batch_data[1]\n",
        "print(imgs.shape, imgs[0].dtype, lbls.shape, lbls[0].dtype)\n",
        "\n",
        "train_images = jnp.array(train_dataset.data).reshape(len(train_dataset), -1)\n",
        "train_lbls = jnp.array(train_dataset.targets)\n",
        "\n",
        "test_images = jnp.array(test_dataset.data).reshape(len(test_dataset), -1)\n",
        "test_lbls = jnp.array(test_dataset.targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PpapXlEi8kZ",
        "outputId": "4ddc3b03-7ccc-430c-b20a-16d22d941617"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784,)\n",
            "(128, 784) float32 (128,) int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(params, imgs, gt_lbls):\n",
        "    return -jnp.mean(batched_MLP_predict(params, imgs) * gt_lbls)\n",
        "\n",
        "def accuracy(params, dataset_imgs, dataset_lbls):\n",
        "    pred_classes = jnp.argmax(batched_MLP_predict(params, dataset_imgs), axis=1)\n",
        "    return jnp.mean(dataset_lbls == pred_classes)\n",
        "\n",
        "@jit\n",
        "def update(params, imgs, gt_lbls, lr=0.01):\n",
        "    loss, grads = value_and_grad(loss_func)(params, imgs, gt_lbls)\n",
        "\n",
        "    return loss, jax.tree_multimap(lambda p, g: p - lr*g, params, grads)\n",
        "\n",
        "# Create a MLP\n",
        "MLP_params = perceptron([np.prod((28,28)), 512, 256, len(MNIST.classes)], key)\n",
        "for epoch in range(5):\n",
        "    for cnt, (imgs, lbls) in enumerate(train_loader):\n",
        "        gt_labels = jax.nn.one_hot(lbls, len(MNIST.classes))\n",
        "        loss, MLP_params = update(MLP_params, imgs, gt_labels)\n",
        "        if cnt % 50 == 0:\n",
        "            print(loss)\n",
        "\n",
        "    print(f'Epoch {epoch}, train acc = {accuracy(MLP_params, train_images, train_lbls)} test acc = {accuracy(MLP_params, test_images, test_lbls)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niJ-hp5xjC0i",
        "outputId": "b16e0514-4aa3-45bd-fb57-cfc2c829022d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24260469\n",
            "0.09087726\n",
            "0.053342488\n",
            "0.042885616\n",
            "0.047708005\n",
            "0.02604251\n",
            "0.03798076\n",
            "0.021008145\n",
            "0.039591707\n",
            "0.043994814\n",
            "Epoch 0, train acc = 0.9143999814987183 test acc = 0.9177999496459961\n",
            "0.027869707\n",
            "0.025654862\n",
            "0.022173157\n",
            "0.02054069\n",
            "0.03394743\n",
            "0.024394639\n",
            "0.032333013\n",
            "0.030117124\n",
            "0.025959974\n",
            "0.01813677\n",
            "Epoch 1, train acc = 0.9363999962806702 test acc = 0.9355999827384949\n",
            "0.01898101\n",
            "0.017320886\n",
            "0.013933412\n",
            "0.022037804\n",
            "0.019508507\n",
            "0.01611787\n",
            "0.024927486\n",
            "0.029355094\n",
            "0.02862677\n",
            "0.017472556\n",
            "Epoch 2, train acc = 0.946316659450531 test acc = 0.9436999559402466\n",
            "0.019586999\n",
            "0.014580408\n",
            "0.02541149\n",
            "0.02045689\n",
            "0.015024898\n",
            "0.017970493\n",
            "0.01809365\n",
            "0.009693205\n",
            "0.013777402\n",
            "0.011030308\n",
            "Epoch 3, train acc = 0.9528666734695435 test acc = 0.949999988079071\n",
            "0.010929279\n",
            "0.02372255\n",
            "0.013016467\n",
            "0.012304547\n",
            "0.017461935\n",
            "0.015203603\n",
            "0.013762377\n",
            "0.012463077\n",
            "0.015798276\n",
            "0.011212924\n",
            "Epoch 4, train acc = 0.9581833481788635 test acc = 0.9542999863624573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "imgs, lbls = next(iter(test_loader))\n",
        "img = imgs[4].reshape((28, 28))\n",
        "print('preiction: ', jnp.argmax(predict(MLP_params, np.ravel(img))))\n",
        "print('actual: ', lbls[4])\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SSvba1AsjJlP",
        "outputId": "425a2d3b-a21e-423b-fc15-ce486738d2a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preiction:  4\n",
            "actual:  4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}